{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVrPVDzx9AD0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.9' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.13 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# @title Setup\n",
        "\n",
        "import asyncio\n",
        "from collections.abc import Generator\n",
        "import copy\n",
        "import json\n",
        "import random\n",
        "\n",
        "from colabtools import adhoc_import\n",
        "from colabtools import proto\n",
        "\n",
        "with adhoc_import.Google3Head():\n",
        "  from google3.net.rpc.python.contrib.dynamic_stubby import stubby2\n",
        "\n",
        "from google3.learning.deepmind.evergreen.model_access.client.python import model_client\n",
        "\n",
        "API_KEY = ''  # @param {type: 'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Caya3LhHmvg"
      },
      "outputs": [],
      "source": [
        "# @title Generate scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIR-mOYJ3-_I"
      },
      "outputs": [],
      "source": [
        "SCENARIO_TEMPLATE = \"\"\"\n",
        "Your task is to generate a variety of meeting scenarios and user personas for\n",
        "use in generating meeting transcripts. These users will ultimately interact with\n",
        "an AI agent in a meeting.\n",
        "\n",
        "An example output of content is below:\n",
        "\n",
        "scenario: This is a meeting to get leadership input on the current plan of the Meet Voice\n",
        "Agent project. The project is due to launch in June 2026 but the current scope\n",
        "(large) and staffing (small) puts the timeline at risk.\n",
        "\n",
        "participants:\n",
        "Anne: Engineering leader reviewing the team's plan, wants to understand the\n",
        "tradeoff between pushing out the launch date vs. cutting scope.\n",
        "Bob: Product leader helping explain the key use cases for the project\n",
        "Carol: Presenting the project and explaining the risks and technical complexities,\n",
        "proposes pushing out the launch date but wants feedback.\n",
        "Dylan: Mostly listening, asks an occasional clarifying question.\n",
        "\n",
        "participant_names:\n",
        "Anne\n",
        "Bob\n",
        "Carol\n",
        "Dylan\n",
        "\n",
        "Please output the list of scenarios in json format; each scenario should have\n",
        "the keys \"\"scenario\"\", \"\"participants\"\", and \"\"participant_names\"\". Participants\n",
        "should be output as a single string, with each participant on a new line.\n",
        "\n",
        "All scenarios should adhere to the following guidance:\n",
        "{scenario_guidance}\n",
        "\n",
        "Specific guidance on user personas:\n",
        "{user_guidance}\n",
        "\n",
        "Please output 3 scenarios and corresponding participant personas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RA2y6AKlE5z"
      },
      "outputs": [],
      "source": [
        "scenario_client = model_client.ModelClient(\n",
        "    model_url=\"gemini-api:/models/gemini-2.5-pro\",\n",
        "    api_key=API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkr4jdHjzvj6"
      },
      "outputs": [],
      "source": [
        "def generate_scenario_prompt(scenario_guidance, user_guidance):\n",
        "  return SCENARIO_TEMPLATE.format(\n",
        "      scenario_guidance=scenario_guidance,\n",
        "      user_guidance=user_guidance,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdH2j5bW4HiL"
      },
      "outputs": [],
      "source": [
        "scenario_guidance = \"\"\"\n",
        "Decide on a restaurant\n",
        "User wants help to decide on a restaurant.\n",
        "\"\"\"\n",
        "\n",
        "user_guidance = \"\"\"\n",
        "There should be {num_users} users defined.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj8dsyos7GO9"
      },
      "outputs": [],
      "source": [
        "scenarios_list = []\n",
        "for num_users in range(1, 6):\n",
        "  scenario_response = scenario_client.generate(\n",
        "      generate_scenario_prompt(\n",
        "          scenario_guidance, user_guidance.format(num_users=num_users)\n",
        "      ),\n",
        "      config=model_client.make_generation_config(temperature=1.0),\n",
        "  )\n",
        "  scenarios_list = scenarios_list + json.loads(\n",
        "      scenario_response.as_text().replace(\"`\", \"\").replace(\"json\\n\", \"\")\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 34
        },
        "executionInfo": {
          "elapsed": 55,
          "status": "ok",
          "timestamp": 1768496646360,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "TnjlgRPK6WuE",
        "outputId": "8e3b6685-7992-41d8-b817-f6a77a36ca3a"
      },
      "outputs": [],
      "source": [
        "with open(\"/tmp/restaurant_scenarios.json\", \"w\") as json_file:\n",
        "  # Use json.dump() to write the data to the file\n",
        "  json.dump(scenarios_list, json_file, indent=4)\n",
        "\n",
        "%download_file /tmp/restaurant_scenarios.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1768496646639,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "eUaPoBOFzgEv",
        "outputId": "ccfa4d0e-4652-4e48-f7ef-01d9308b1062"
      },
      "outputs": [],
      "source": [
        "for i, scenario_dict in enumerate(scenarios_list):\n",
        "  print('#######################################')\n",
        "  scenario = scenario_dict['scenario']\n",
        "  print(f'Scenario {i}: {scenario}\\n')\n",
        "  participants = scenario_dict['participants']\n",
        "  print(f'Participants: \\n{participants}\\n\\n')\n",
        "  participant_names = scenario_dict['participant_names']\n",
        "  print(f'Participant names: {participant_names}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQjtqJfP-XzY"
      },
      "source": [
        "# Transcript generation from scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPgNnIwv9YsK"
      },
      "outputs": [],
      "source": [
        "AUTOUSER_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert dialog simulator.\n",
        "Your job is to simulate the next turn in the given dialog with the given scenario as context.\n",
        "You need to select a participant from the list to make the next turn and decide what they say.\n",
        "Only use participants that are found in the given list.\n",
        "Participants should not compliment each other on their ideas or summarize the conversation in every turn;\n",
        "most responses should be short and not overly friendly or pandering. We want\n",
        "participant responses to simulate what would be said aloud in a live meeting or discussion as\n",
        "much as possible.\n",
        "\n",
        "The output format should be for example:\n",
        "David: I love bananas.\n",
        "\n",
        "# Scenario\n",
        "{scenario}\n",
        "\n",
        "# Participants:\n",
        "{participants}\n",
        "Gemini: an AI agent called Gemini available to provide info or help as needed.\n",
        "The agent should not hallucinate or makeup information, and should use Google search when needed to find info.\n",
        "Gemini does not have any context on the scenario other than what is said by users.\n",
        "{agent_guidance}\n",
        "\n",
        "# Dialog:\n",
        "{dialog_history}\n",
        "\n",
        "# Next turn:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LECuz5jnKvOL"
      },
      "outputs": [],
      "source": [
        "agent_guidance = \"\"\"\n",
        "The agent should be short and snappy, and only respond when there is value to be added.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYi3HOSezgCZ"
      },
      "outputs": [],
      "source": [
        "def format_participants_list(participants_list):\n",
        "  # Shuffle participants.\n",
        "  plist = participants_list.split(\"\\n\")\n",
        "  plist = [p.strip() for p in plist if p.strip()]\n",
        "  random.shuffle(plist)\n",
        "  plist = \"\\n\".join(plist)\n",
        "  return plist\n",
        "\n",
        "\n",
        "def format_dialog_history(x):\n",
        "  return x\n",
        "\n",
        "\n",
        "def get_autouser_prompt(\n",
        "    scenario: str, agent_guidance: str, participants_list, dialog_history\n",
        "):\n",
        "  return AUTOUSER_PROMPT_TEMPLATE.format(\n",
        "      scenario=scenario,\n",
        "      agent_guidance=agent_guidance,\n",
        "      participants=format_participants_list(participants_list),\n",
        "      dialog_history=format_dialog_history(dialog_history),\n",
        "  )\n",
        "\n",
        "\n",
        "def get_autouser_turn(\n",
        "    autouser_client,\n",
        "    scenario: str,\n",
        "    agent_guidance: str,\n",
        "    participants_list: str,\n",
        "    dialog_history: str,\n",
        "):\n",
        "  autouser_prompt = get_autouser_prompt(\n",
        "      scenario, agent_guidance, participants_list, dialog_history\n",
        "  )\n",
        "  autouser_response = autouser_client.generate(\n",
        "      autouser_prompt,\n",
        "      config=model_client.make_generation_config(temperature=1.0),\n",
        "  )\n",
        "\n",
        "  turn_participant, turn_text = parse_response(autouser_response)\n",
        "  return (turn_participant, turn_text)\n",
        "\n",
        "\n",
        "def parse_response(response):\n",
        "  turn_participant, turn_text = response.as_text().split(\":\", maxsplit=1)\n",
        "  turn_participant = turn_participant.strip()\n",
        "  turn_text = turn_text.strip()\n",
        "  return turn_participant, turn_text\n",
        "\n",
        "\n",
        "def extend_dialog_history(dialog_history, turn_participant, turn_text):\n",
        "  return dialog_history.strip() + f\"\\n{turn_participant}: {turn_text}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_2Upef5BZm0"
      },
      "outputs": [],
      "source": [
        "NUM_TURNS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb2utSHv_rH5"
      },
      "outputs": [],
      "source": [
        "def generate_transcript(\n",
        "    scenario: str, agent_guidance: str, participant, participant_names\n",
        "):\n",
        "  dialog_history = \"\"\n",
        "\n",
        "  autouser_client = model_client.ModelClient(\n",
        "      model_url=\"gemini-api:/models/gemini-2.5-pro\",\n",
        "      api_key=API_KEY,\n",
        "  )\n",
        "\n",
        "  participants\n",
        "\n",
        "  for turn in range(0, NUM_TURNS):\n",
        "    turn_participant, turn_text = get_autouser_turn(\n",
        "        autouser_client,\n",
        "        scenario,\n",
        "        agent_guidance,\n",
        "        participants,\n",
        "        dialog_history,\n",
        "    )\n",
        "    last_turn = f\"{turn_participant}: {turn_text}\"\n",
        "    print(last_turn)\n",
        "    if turn_participant not in participant_names:\n",
        "      print(f\"Error: unknown participant: {turn_participant}\")\n",
        "    dialog_history = extend_dialog_history(\n",
        "        dialog_history, turn_participant, turn_text\n",
        "    )\n",
        "\n",
        "  return dialog_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 1670713,
          "status": "error",
          "timestamp": 1768498857537,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "9EksK2hJzf_y",
        "outputId": "e0600070-cf69-466c-e315-9ea84197afb5"
      },
      "outputs": [],
      "source": [
        "scenarios_with_transcripts = []\n",
        "for i, scenario_dict in enumerate(scenarios_list):\n",
        "  print('#######################################')\n",
        "  scenario = scenario_dict['scenario']\n",
        "  print(f'Scenario {i}: {scenario}\\n')\n",
        "  participants = scenario_dict['participants']\n",
        "  print(f'Participants: \\n{participants}\\n\\n')\n",
        "  participant_names = scenario_dict['participant_names'] + ['Gemini']\n",
        "\n",
        "  transcript = generate_transcript(\n",
        "      scenario, agent_guidance, participants, participant_names\n",
        "  )\n",
        "  scenario_dict['transcript'] = transcript\n",
        "  scenarios_with_transcripts.append(scenario_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 34
        },
        "executionInfo": {
          "elapsed": 56,
          "status": "ok",
          "timestamp": 1768498860020,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "nZL6TiGIC27d",
        "outputId": "bdc43ced-4a23-4d7b-97e7-1d92ddd51f4b"
      },
      "outputs": [],
      "source": [
        "with open(\"/tmp/restaurant_scenarios_with_transcripts.json\", \"w\") as json_file:\n",
        "  json.dump(scenarios_with_transcripts, json_file, indent=4)\n",
        "\n",
        "%download_file /tmp/restaurant_scenarios_with_transcripts.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rEb503rRVns"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "name": "scenario_and_dialogue_generation.ipynb",
      "provenance": [
        {
          "file_id": "/piper/depot/google3/communication/media/voice_agent/colab/open_ended_conversation_generation.ipynb",
          "timestamp": 1767794317848
        },
        {
          "file_id": "1ToiBULabHv1k_JOsjzPteDrccvWfZtsd",
          "timestamp": 1766082380927
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
